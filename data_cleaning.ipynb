{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc76b233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srefmon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>First Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Second Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fourth Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Third Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fourth Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311753</th>\n",
       "      <td>Third Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311754</th>\n",
       "      <td>Fourth Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311755</th>\n",
       "      <td>Third Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311756</th>\n",
       "      <td>First Reference month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311757</th>\n",
       "      <td>Second Reference month</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311758 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       srefmon\n",
       "0        First Reference month\n",
       "1       Second Reference month\n",
       "2       Fourth Reference month\n",
       "3        Third Reference month\n",
       "4       Fourth Reference month\n",
       "...                        ...\n",
       "311753   Third Reference month\n",
       "311754  Fourth Reference month\n",
       "311755   Third Reference month\n",
       "311756   First Reference month\n",
       "311757  Second Reference month\n",
       "\n",
       "[311758 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w7[['srefmon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b1eddf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Wave 7 and 9 core files...\n",
      "Processing Topical modules (assets)...\n",
      "Loading t3...\n",
      "Loading t6...\n",
      "Loading t9...\n",
      "Loading t12...\n",
      "Merging datasets...\n",
      "Merging t3 into main_df...\n",
      "Merging t9 into main_df...\n",
      "Merging t12 into main_df...\n",
      "Merging t7...\n",
      "Merging w7...\n",
      "Merge complete. Main DataFrame shape: (80245, 64)\n",
      "Success! Data merged.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "\n",
    "# ==========================================\n",
    "# 0. 设置路径与辅助函数 (修复数据类型问题的核心)\n",
    "# ==========================================\n",
    "\n",
    "def clean_ids(df):\n",
    "    \"\"\"\n",
    "    强制将合并键 (Merge Keys) 转换为标准字符串类型。\n",
    "    这是解决 merge 结果为空的关键步骤。\n",
    "    \"\"\"\n",
    "    keys = ['ssuid', 'shhadid', 'epppnum']\n",
    "    for col in keys:\n",
    "        if col in df.columns:\n",
    "            # 1. 如果是 Categorical，先转回原始值\n",
    "            if isinstance(df[col].dtype, pd.CategoricalDtype):\n",
    "                df[col] = df[col].astype(object)\n",
    "            # 2. 强制转为字符串，并去除可能的空格\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def load_stata(filename):\n",
    "    \"\"\"读取 Stata 文件并立即清洗主键\"\"\"\n",
    "    df = pd.read_stata(filename)\n",
    "    df = clean_ids(df)\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 1. 预处理 Core (w) 文件\n",
    "# ==========================================\n",
    "print(\"Processing Wave 7 and 9 core files...\")\n",
    "\n",
    "# 读取 w7\n",
    "w7 = load_stata(\"w7.dta\")\n",
    "w7_v2 = w7[w7['srefmon'] == 4].copy()\n",
    "# 再次确保 ID 清洗（以防万一）\n",
    "w7_v2 = clean_ids(w7_v2) \n",
    "\n",
    "# 读取 w9\n",
    "w9 = load_stata(\"w9.dta\")\n",
    "w9_v2 = w9[w9['srefmon'] == 4].copy()\n",
    "w9_v2 = clean_ids(w9_v2)\n",
    "\n",
    "# ==========================================\n",
    "# 2. 预处理 Topical (t) 文件\n",
    "# ==========================================\n",
    "print(\"Processing Topical modules (assets)...\")\n",
    "\n",
    "asset_vars = [\n",
    "    'taltb', 'thhintbk', 'thhintot', 'thhotast', 'thhira', \n",
    "    'thhscdbt', 'rhhuscbt', 'rhhstk', 'tcarval1', 'tcarval2', 'tcarval3'\n",
    "]\n",
    "\n",
    "t_data = {} \n",
    "\n",
    "for wave in [3, 6, 9, 12]:\n",
    "    print(f\"Loading t{wave}...\")\n",
    "    df = load_stata(f\"t{wave}.dta\")\n",
    "    \n",
    "    rename_dict = {var: f\"{var}{wave}\" for var in asset_vars}\n",
    "    df = df.rename(columns=rename_dict)\n",
    "    \n",
    "    t_data[wave] = df\n",
    "\n",
    "# ==========================================\n",
    "# 3. 合并数据 (Merge) - 修正版\n",
    "# ==========================================\n",
    "print(\"Merging datasets...\")\n",
    "\n",
    "main_df = t_data[6].copy()\n",
    "\n",
    "# 保留 t6 中的关键变量\n",
    "# 注意：Stata代码中 keep ssuid... 实际上暗示了以 t6 的样本为基础\n",
    "keep_cols_t6 = ['ssuid', 'shhadid', 'epppnum', 'tage', 'eeducate'] + \\\n",
    "               [f\"{var}6\" for var in asset_vars]\n",
    "main_df = main_df[keep_cols_t6]\n",
    "\n",
    "# 定义合并键\n",
    "merge_keys = ['ssuid', 'shhadid', 'epppnum']\n",
    "\n",
    "# 修正策略：改用 how='left'。\n",
    "# 理由：Gelber 的研究是基于 \"第一年(Year 1)\" 的状态来追踪后续变化。\n",
    "# t6 对应 Wave 6 (Year 1 的开始)，如果一个人在 t6 存在，但在 t12 消失了，\n",
    "# 我们希望保留这条记录（尽管后续计算差分时可能因缺值而被丢弃），\n",
    "# 而不是在这一步就因为 inner join 把他删掉。\n",
    "# 此外，Stata 的默认 merge 行为保留 Master (t6) 的所有行。\n",
    "\n",
    "for wave in [3, 9, 12]:\n",
    "    print(f\"Merging t{wave} into main_df...\")\n",
    "    cols_to_keep = merge_keys + [f\"{var}{wave}\" for var in asset_vars]\n",
    "    \n",
    "    # 检查被合并的数据是否为空\n",
    "    if t_data[wave].empty:\n",
    "        print(f\"Warning: t{wave} is empty!\")\n",
    "        \n",
    "    main_df = pd.merge(main_df, t_data[wave][cols_to_keep], on=merge_keys, how='left')\n",
    "\n",
    "# t7 包含资格信息，非常重要\n",
    "print(\"Merging t7...\")\n",
    "t7 = load_stata(\"t7.dta\")\n",
    "t7_cols = merge_keys + ['enoina03', 'enoinb03', 'epensnyn', 'etdeffen', 'e1taxdef', 'e2taxdef', 'e3taxdef']\n",
    "main_df = pd.merge(main_df, t7[t7_cols], on=merge_keys, how='left')\n",
    "\n",
    "print(\"Merging w7...\")\n",
    "w7_cols = merge_keys + ['tsjdate1', 'srotaton', 'wpfinwgt', 'eclwrk1', 'efnp', 'esex', 'tempall1', 'ejbind1']\n",
    "main_df = pd.merge(main_df, w7_v2[w7_cols], on=merge_keys, how='left')\n",
    "\n",
    "print(f\"Merge complete. Main DataFrame shape: {main_df.shape}\")\n",
    "\n",
    "# 检查点：如果这里行数还是 0，那就是原始数据有问题（例如文件名不对或数据确实没读进来）\n",
    "if len(main_df) == 0:\n",
    "    raise ValueError(\"Error: main_df is empty after merging. Check input files and ID columns.\")\n",
    "else:\n",
    "    print(\"Success! Data merged.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74448d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ssuid</th>\n",
       "      <th>shhadid</th>\n",
       "      <th>epppnum</th>\n",
       "      <th>tage</th>\n",
       "      <th>eeducate</th>\n",
       "      <th>taltb6</th>\n",
       "      <th>thhintbk6</th>\n",
       "      <th>thhintot6</th>\n",
       "      <th>thhotast6</th>\n",
       "      <th>thhira6</th>\n",
       "      <th>...</th>\n",
       "      <th>e2taxdef</th>\n",
       "      <th>e3taxdef</th>\n",
       "      <th>tsjdate1</th>\n",
       "      <th>srotaton</th>\n",
       "      <th>wpfinwgt</th>\n",
       "      <th>eclwrk1</th>\n",
       "      <th>efnp</th>\n",
       "      <th>esex</th>\n",
       "      <th>tempall1</th>\n",
       "      <th>ejbind1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>019003754630</td>\n",
       "      <td>21</td>\n",
       "      <td>0101</td>\n",
       "      <td>45</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>019003754630</td>\n",
       "      <td>21</td>\n",
       "      <td>0201</td>\n",
       "      <td>50</td>\n",
       "      <td>High school graduate - high</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>019003754630</td>\n",
       "      <td>21</td>\n",
       "      <td>0202</td>\n",
       "      <td>11</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>019003754630</td>\n",
       "      <td>21</td>\n",
       "      <td>0203</td>\n",
       "      <td>21</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>019003754630</td>\n",
       "      <td>21</td>\n",
       "      <td>0204</td>\n",
       "      <td>24</td>\n",
       "      <td>11th grade</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80240</th>\n",
       "      <td>960562332932</td>\n",
       "      <td>11</td>\n",
       "      <td>0101</td>\n",
       "      <td>61</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>17000</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80241</th>\n",
       "      <td>960562332932</td>\n",
       "      <td>11</td>\n",
       "      <td>0102</td>\n",
       "      <td>55</td>\n",
       "      <td>Bachelors degree (For example:</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80242</th>\n",
       "      <td>960562332932</td>\n",
       "      <td>61</td>\n",
       "      <td>0103</td>\n",
       "      <td>29</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>928.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>250.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80243</th>\n",
       "      <td>960562332932</td>\n",
       "      <td>61</td>\n",
       "      <td>0501</td>\n",
       "      <td>31</td>\n",
       "      <td>Some college but no degree</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>928.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>250.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80244</th>\n",
       "      <td>960562398689</td>\n",
       "      <td>11</td>\n",
       "      <td>0101</td>\n",
       "      <td>57</td>\n",
       "      <td>Bachelors degree (For example:</td>\n",
       "      <td>None or not in universe</td>\n",
       "      <td>464.0</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>None or Not in universe</td>\n",
       "      <td>...</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>Not in universe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80245 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ssuid shhadid epppnum tage                        eeducate  \\\n",
       "0      019003754630      21    0101   45      Some college but no degree   \n",
       "1      019003754630      21    0201   50     High school graduate - high   \n",
       "2      019003754630      21    0202   11                 Not in universe   \n",
       "3      019003754630      21    0203   21                 Not in universe   \n",
       "4      019003754630      21    0204   24                      11th grade   \n",
       "...             ...     ...     ...  ...                             ...   \n",
       "80240  960562332932      11    0101   61      Some college but no degree   \n",
       "80241  960562332932      11    0102   55  Bachelors degree (For example:   \n",
       "80242  960562332932      61    0103   29      Some college but no degree   \n",
       "80243  960562332932      61    0501   31      Some college but no degree   \n",
       "80244  960562398689      11    0101   57  Bachelors degree (For example:   \n",
       "\n",
       "                        taltb6                thhintbk6  \\\n",
       "0      None or not in universe  None or Not in universe   \n",
       "1      None or not in universe  None or Not in universe   \n",
       "2      None or not in universe  None or Not in universe   \n",
       "3      None or not in universe  None or Not in universe   \n",
       "4      None or not in universe  None or Not in universe   \n",
       "...                        ...                      ...   \n",
       "80240                    17000                   4500.0   \n",
       "80241  None or not in universe                   4500.0   \n",
       "80242  None or not in universe                    928.0   \n",
       "80243  None or not in universe                    928.0   \n",
       "80244  None or not in universe                    464.0   \n",
       "\n",
       "                     thhintot6                thhotast6  \\\n",
       "0      None or Not in universe  None or Not in universe   \n",
       "1      None or Not in universe  None or Not in universe   \n",
       "2      None or Not in universe  None or Not in universe   \n",
       "3      None or Not in universe  None or Not in universe   \n",
       "4      None or Not in universe  None or Not in universe   \n",
       "...                        ...                      ...   \n",
       "80240  None or Not in universe                   5600.0   \n",
       "80241  None or Not in universe                   5600.0   \n",
       "80242  None or Not in universe                    250.0   \n",
       "80243  None or Not in universe                    250.0   \n",
       "80244  None or Not in universe  None or Not in universe   \n",
       "\n",
       "                       thhira6  ...         e2taxdef         e3taxdef  \\\n",
       "0      None or Not in universe  ...  Not in universe               No   \n",
       "1      None or Not in universe  ...  Not in universe  Not in universe   \n",
       "2      None or Not in universe  ...  Not in universe  Not in universe   \n",
       "3      None or Not in universe  ...  Not in universe  Not in universe   \n",
       "4      None or Not in universe  ...  Not in universe               No   \n",
       "...                        ...  ...              ...              ...   \n",
       "80240                    700.0  ...  Not in universe  Not in universe   \n",
       "80241                    700.0  ...  Not in universe  Not in universe   \n",
       "80242  None or Not in universe  ...  Not in universe               No   \n",
       "80243  None or Not in universe  ...  Not in universe  Not in universe   \n",
       "80244  None or Not in universe  ...  Not in universe  Not in universe   \n",
       "\n",
       "      tsjdate1 srotaton wpfinwgt eclwrk1 efnp esex tempall1 ejbind1  \n",
       "0          NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "1          NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "2          NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "3          NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "4          NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "...        ...      ...      ...     ...  ...  ...      ...     ...  \n",
       "80240      NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "80241      NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "80242      NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "80243      NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "80244      NaN      NaN      NaN     NaN  NaN  NaN      NaN     NaN  \n",
       "\n",
       "[80245 rows x 64 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ffe9f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_numeric = ['srotaton', 'tsjdate1', 'eclwrk1', 'tage']\n",
    "\n",
    "for col in cols_to_numeric:\n",
    "    if col in main_df.columns:\n",
    "        main_df[col] = pd.to_numeric(main_df[col], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6703958a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing variables...\n"
     ]
    },
    {
     "ename": "IntCastingNaNError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIntCastingNaNError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     14\u001b[39m main_df[\u001b[33m'\u001b[39m\u001b[33myr1jb1\u001b[39m\u001b[33m'\u001b[39m] = np.select(conditions, [\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m], default=\u001b[32m0\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# 4.2 构造 daysonjob (在职天数) [cite: 1318-1321]\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 这是一个简化的日期计算，Stata代码使用整数运算来近似日期\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m main_df[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43m(\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtsjdate1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m main_df[\u001b[33m'\u001b[39m\u001b[33mmo\u001b[39m\u001b[33m'\u001b[39m] = ((main_df[\u001b[33m'\u001b[39m\u001b[33mtsjdate1\u001b[39m\u001b[33m'\u001b[39m] - main_df[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m]*\u001b[32m10000\u001b[39m) / \u001b[32m100\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m     20\u001b[39m main_df[\u001b[33m'\u001b[39m\u001b[33mday\u001b[39m\u001b[33m'\u001b[39m] = (main_df[\u001b[33m'\u001b[39m\u001b[33mtsjdate1\u001b[39m\u001b[33m'\u001b[39m] - main_df[\u001b[33m'\u001b[39m\u001b[33myear\u001b[39m\u001b[33m'\u001b[39m]*\u001b[32m10000\u001b[39m - main_df[\u001b[33m'\u001b[39m\u001b[33mmo\u001b[39m\u001b[33m'\u001b[39m]*\u001b[32m100\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/generic.py:6643\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6637\u001b[39m     results = [\n\u001b[32m   6638\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6639\u001b[39m     ]\n\u001b[32m   6641\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6642\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6643\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6644\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6645\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/internals/managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/internals/managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/internals/blocks.py:758\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    755\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    756\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    760\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    762\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:101\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m lib.ensure_string_array(\n\u001b[32m     97\u001b[39m         arr, skipna=skipna, convert_na_value=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     98\u001b[39m     ).reshape(shape)\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m np.issubdtype(arr.dtype, np.floating) \u001b[38;5;129;01mand\u001b[39;00m dtype.kind \u001b[38;5;129;01min\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33miu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_astype_float_to_int_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    104\u001b[39m     \u001b[38;5;66;03m# if we have a datetime/timedelta array of objects\u001b[39;00m\n\u001b[32m    105\u001b[39m     \u001b[38;5;66;03m# then coerce to datetime64[ns] and use DatetimeArray.astype\u001b[39;00m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m lib.is_np_dtype(dtype, \u001b[33m\"\u001b[39m\u001b[33mM\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env_214/lib/python3.13/site-packages/pandas/core/dtypes/astype.py:145\u001b[39m, in \u001b[36m_astype_float_to_int_nansafe\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    141\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03mastype with a check preventing converting NaN to an meaningless integer value.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np.isfinite(values).all():\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m IntCastingNaNError(\n\u001b[32m    146\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCannot convert non-finite values (NA or inf) to integer\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m     )\n\u001b[32m    148\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.kind == \u001b[33m\"\u001b[39m\u001b[33mu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    149\u001b[39m     \u001b[38;5;66;03m# GH#45151\u001b[39;00m\n\u001b[32m    150\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (values >= \u001b[32m0\u001b[39m).all():\n",
      "\u001b[31mIntCastingNaNError\u001b[39m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 4. 变量构造 (Feature Engineering)\n",
    "# ==========================================\n",
    "print(\"Constructing variables...\")\n",
    "\n",
    "# 4.1 构造 yr1jb1: 是否在工作第一年 [cite: 1315-1317]\n",
    "# 逻辑：根据 rotation group (轮换组) 和开始工作日期判断\n",
    "conditions = [\n",
    "    (main_df['srotaton'] == 1) & (main_df['tsjdate1'] > 19970299),\n",
    "    (main_df['srotaton'] == 2) & (main_df['tsjdate1'] > 19970399),\n",
    "    (main_df['srotaton'] == 3) & (main_df['tsjdate1'] > 19970499),\n",
    "    (main_df['srotaton'] == 4) & (main_df['tsjdate1'] > 19970599)\n",
    "]\n",
    "main_df['yr1jb1'] = np.select(conditions, [1, 1, 1, 1], default=0)\n",
    "\n",
    "# 4.2 构造 daysonjob (在职天数) [cite: 1318-1321]\n",
    "# 这是一个简化的日期计算，Stata代码使用整数运算来近似日期\n",
    "main_df['year'] = (main_df['tsjdate1'] / 10000).astype(int)\n",
    "main_df['mo'] = ((main_df['tsjdate1'] - main_df['year']*10000) / 100).astype(int)\n",
    "main_df['day'] = (main_df['tsjdate1'] - main_df['year']*10000 - main_df['mo']*100).astype(int)\n",
    "\n",
    "main_df['daysonjob'] = np.nan\n",
    "# 这里的循环逻辑是对不同年份入职的人计算到1998年的大致天数\n",
    "# 注意：原代码有一个循环 forval i = 1947/1998，这里用向量化操作简化\n",
    "for rot, offset in [(1, 3), (2, 4), (3, 5), (4, 6)]:\n",
    "    mask = (main_df['srotaton'] == rot)\n",
    "    # 逻辑：((1998 - year) * 12 + offset - mo) * 30 + (30 - day)\n",
    "    main_df.loc[mask, 'daysonjob'] = (\n",
    "        (1998 - main_df.loc[mask, 'year']) * 12 + offset - main_df.loc[mask, 'mo']\n",
    "    ) * 30 + (30 - main_df.loc[mask, 'day'])\n",
    "\n",
    "# 4.3 筛选样本 [cite: 1323-1324]\n",
    "# 筛选私营企业 (eclwrk1==1) 且 年龄在 21-65 之间\n",
    "main_df = main_df[\n",
    "    (main_df['eclwrk1'] == 1) & \n",
    "    (main_df['tage'] > 21) & \n",
    "    (main_df['tage'] < 65)\n",
    "].copy()\n",
    "\n",
    "# ==========================================\n",
    "# [cite_start]4.4 汇总汽车价值和金融资产 [cite: 1326-1327]\n",
    "# ==========================================\n",
    "print(\"Summing up assets (fixing data types first)...\")\n",
    "\n",
    "# 【新增修复】：定义所有参与计算的原始资产变量前缀\n",
    "raw_asset_vars = [\n",
    "    'tcarval1', 'tcarval2', 'tcarval3',  # 汽车\n",
    "    'thhintbk', 'thhintot', 'rhhstk', 'thhotast' # 金融资产\n",
    "]\n",
    "\n",
    "for w in [3, 6, 9, 12]:\n",
    "    # 1. 先把参与计算的列全部强制转为数值型 (float)\n",
    "    # 这一步会把非数字（如 \"None\" 或 Stata标签）转为 NaN\n",
    "    for prefix in raw_asset_vars:\n",
    "        col_name = f\"{prefix}{w}\"\n",
    "        if col_name in main_df.columns:\n",
    "            main_df[col_name] = pd.to_numeric(main_df[col_name], errors='coerce')\n",
    "\n",
    "    # 2. 然后再进行加法运算和填充 0\n",
    "    # 计算汽车总值 (Total Car Value)\n",
    "    main_df[f'tcarval{w}'] = (\n",
    "        main_df[f'tcarval1{w}'].fillna(0) + \n",
    "        main_df[f'tcarval2{w}'].fillna(0) + \n",
    "        main_df[f'tcarval3{w}'].fillna(0)\n",
    "    )\n",
    "    \n",
    "    # 计算其他金融资产 (Other Financial Assets)\n",
    "    main_df[f'otherassets{w}'] = (\n",
    "        main_df[f'thhintbk{w}'].fillna(0) + \n",
    "        main_df[f'thhintot{w}'].fillna(0) + \n",
    "        main_df[f'rhhstk{w}'].fillna(0) + \n",
    "        main_df[f'thhotast{w}'].fillna(0)\n",
    "    )\n",
    "\n",
    "# 4.5 合并 Year 2 的工作日期 [cite: 1330]\n",
    "main_df = pd.merge(main_df, w9_v2[merge_keys + ['tsjdate1']], on=merge_keys, how='left', suffixes=('', '_w9'))\n",
    "\n",
    "# 4.6 构造处理变量 \"temp\" (Main Treatment Variable) [cite: 1333]\n",
    "# 逻辑：因等待期(waiting period)而暂时不符合401k资格\n",
    "main_df['temp'] = (\n",
    "    ((main_df['enoina03'] == 1) & (main_df['etdeffen'] == 1)) | \n",
    "    (main_df['enoinb03'] == 1)\n",
    ").astype(int)\n",
    "\n",
    "# ==========================================\n",
    "# 4.7 构造对数差分变量 (Log Differences)\n",
    "# ==========================================\n",
    "print(\"Calculating log differences (fixing data types first)...\")\n",
    "\n",
    "# 定义需要分析的目标变量\n",
    "target_vars = ['taltb', 'thhira', 'otherassets', 'thhscdbt', 'rhhuscbt', 'tcarval']\n",
    "\n",
    "# 【新增修复】：在计算对数之前，确保所有涉及的变量都是数值型\n",
    "# 注意：tcarval 和 otherassets 在前面 4.4 已经算好了（是数值型），\n",
    "# 但 taltb, thhira 等是从原始文件读进来的，可能还是 Categorical，必须转换。\n",
    "for var in target_vars:\n",
    "    for w in [6, 9, 12]:  # 我们只需要 6, 9, 12 波次来计算差分\n",
    "        col_name = f\"{var}{w}\"\n",
    "        if col_name in main_df.columns:\n",
    "            # 强制转为数值，无法转换的变成 NaN\n",
    "            main_df[col_name] = pd.to_numeric(main_df[col_name], errors='coerce')\n",
    "\n",
    "# 开始计算对数差分\n",
    "for var in target_vars:\n",
    "    # 1. 填充空值为 0 (防止加法报错)\n",
    "    # 很多金融资产如果是空值，通常意味着“没有资产”，即 0\n",
    "    val12 = main_df[f'{var}12'].fillna(0)\n",
    "    val9  = main_df[f'{var}9'].fillna(0)\n",
    "    val6  = main_df[f'{var}6'].fillna(0)\n",
    "\n",
    "    # 2. 计算双重差分变量 (d21l...)\n",
    "    # 公式: ln(Year2) - 2*ln(Year1) + ln(Year0)\n",
    "    # +10 是为了避免 log(0)\n",
    "    main_df[f'd21l{var}'] = (\n",
    "        np.log(val12 + 10) - \n",
    "        2 * np.log(val9 + 10) + \n",
    "        np.log(val6 + 10)\n",
    "    )\n",
    "    \n",
    "    # 3. 构造 level 6 的对数 (作为控制变量)\n",
    "    main_df[f'l{var}6'] = np.log(val6 + 10)\n",
    "\n",
    "    # 4. Winsorize (缩尾处理，去除极值)\n",
    "    lower = main_df[f'd21l{var}'].quantile(0.05)\n",
    "    upper = main_df[f'd21l{var}'].quantile(0.95)\n",
    "    main_df[f'd21l{var}w'] = main_df[f'd21l{var}'].clip(lower, upper)\n",
    "\n",
    "# ==========================================\n",
    "# 5. 计算年度总收入 (Heavy Lifting)\n",
    "# ==========================================\n",
    "# 对应 Stata 代码 1338-1358 行\n",
    "# 这一步在原代码中非常繁琐，需要分别加载 w7, w8, w9 的每个月数据并求和。\n",
    "# 下面用 Python 简化逻辑：\n",
    "\n",
    "print(\"Calculating annual income (this might take a while)...\")\n",
    "\n",
    "def calculate_wave_income(filename, wave_num):\n",
    "    \"\"\"读取一个Wave的所有月份，按人汇总收入\"\"\"\n",
    "    df = load_stata(filename)\n",
    "    # 保留需要的列：ID，月份，总收入\n",
    "    subset = df[['ssuid', 'shhadid', 'epppnum', 'srefmon', 'thtotinc']].copy()\n",
    "    # 只要前4个月\n",
    "    subset = subset[subset['srefmon'].isin([1, 2, 3, 4])]\n",
    "    # 按人聚合求和\n",
    "    income_sum = subset.groupby(merge_keys)['thtotinc'].sum().reset_index()\n",
    "    income_sum = income_sum.rename(columns={'thtotinc': f'thtotinc{wave_num}'})\n",
    "    return income_sum\n",
    "\n",
    "# 计算 w7, w8, w9 的收入\n",
    "inc7 = calculate_wave_income(\"w7.dta\", 7)\n",
    "inc8 = calculate_wave_income(\"w8.dta\", 8)\n",
    "inc9 = calculate_wave_income(\"w9.dta\", 9)\n",
    "\n",
    "# 合并到主数据\n",
    "main_df = pd.merge(main_df, inc7, on=merge_keys, how='left')\n",
    "main_df = pd.merge(main_df, inc8, on=merge_keys, how='left')\n",
    "main_df = pd.merge(main_df, inc9, on=merge_keys, how='left')\n",
    "\n",
    "# Year 1 总收入 [cite: 1358]\n",
    "main_df['thtotincyr1'] = (\n",
    "    main_df['thtotinc7'].fillna(0) + \n",
    "    main_df['thtotinc8'].fillna(0) + \n",
    "    main_df['thtotinc9'].fillna(0)\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 6. 最终清洗与样本定义\n",
    "# ==========================================\n",
    "\n",
    "# 构造 y401k: 所在公司是否提供 401k [cite: 1360]\n",
    "# 只要符合资格 OR 暂时不符合 OR 有贡献扣除等，即视为公司提供\n",
    "main_df['y401k'] = (\n",
    "    (main_df['temp'] == 1) |\n",
    "    (main_df['e1taxdef'] == 1) |\n",
    "    (main_df['e2taxdef'] == 1) |\n",
    "    (main_df['e3taxdef'] == 1) |\n",
    "    ((main_df['etdeffen'] == 1) & (main_df['yr1jb1'] == 1))\n",
    ").astype(int)\n",
    "\n",
    "# 生成 Household ID (hid) 用于聚类标准误 [cite: 1362]\n",
    "# 在 Pandas 中，我们可以直接用 ssuid + shhadid 组合作为 Cluster ID\n",
    "main_df['hid'] = main_df.groupby(['ssuid', 'shhadid']).ngroup()\n",
    "\n",
    "# 教育虚拟变量 [cite: 1332]\n",
    "# eeducate 是分类变量，转换为 dummies\n",
    "educ_dummies = pd.get_dummies(main_df['eeducate'], prefix='educ')\n",
    "main_df = pd.concat([main_df, educ_dummies], axis=1)\n",
    "\n",
    "# 处理缺失收入 [cite: 1365-1366]\n",
    "main_df['incmissing'] = main_df['thtotincyr1'].isna().astype(int)\n",
    "main_df['thtotincyr1'] = main_df['thtotincyr1'].fillna(-1)\n",
    "\n",
    "# 生成年龄平方\n",
    "main_df['tagesq'] = main_df['tage'] ** 2\n",
    "\n",
    "# ==========================================\n",
    "# 7. 导出或运行回归 (Replication Table 2)\n",
    "# ==========================================\n",
    "# 仅保留在职第一年且公司有401k的样本 [cite: 1369]\n",
    "analysis_df = main_df[(main_df['yr1jb1'] == 1) & (main_df['y401k'] == 1)].copy()\n",
    "\n",
    "print(f\"Final analysis sample size: {len(analysis_df)}\")\n",
    "\n",
    "# 示例：复现 Table 2 的部分回归 (taltb - Total Assets in 401k) [cite: 1375]\n",
    "# 模型：Y = beta0 + beta1 * temp + controls\n",
    "# 标准误在 Household (hid) 层面聚类\n",
    "\n",
    "print(\"Running sample regression for 401k assets (Table 2 Col 1)...\")\n",
    "\n",
    "# 定义控制变量 (简化版，对应 Panel B)\n",
    "controls = [\n",
    "    'tage', 'tagesq', 'thtotincyr1', 'incmissing', 'daysonjob'\n",
    "    # 注意：为了代码简洁，这里没加所有的 educ*, tempallnew*, ind1dig* 虚拟变量\n",
    "    # 实际运行时你需要把生成的所有 dummy 变量名加进来\n",
    "] \n",
    "formula = f\"d21ltaltb ~ temp + {' + '.join(controls)}\"\n",
    "\n",
    "try:\n",
    "    model = smf.ols(formula=formula, data=analysis_df)\n",
    "    # 使用聚类标准误 (cluster robust standard errors)\n",
    "    results = model.fit(cov_type='cluster', cov_kwds={'groups': analysis_df['hid']})\n",
    "    \n",
    "    print(results.summary())\n",
    "except Exception as e:\n",
    "    print(f\"Regression failed: {e}\")\n",
    "\n",
    "# 保存最终数据以便进一步分析\n",
    "# analysis_df.to_csv(\"replicated_gelber_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_214",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
